<!DOCTYPE html>
<html>
<style> 
	body {
			font-family: Helvetica, Arial, sans-serif;
			font-size: 20px;
			background-color: #009999;
			font-family: "Avenir-Light", Helvetica, "Helvetica Neue", Arial, sans-serif;
			text-color: white;
			text-align: center;
			text-decoration: none;
			background:-o-linear-gradient(-70deg, #009BB9 0%, #0EDCAD 100%);
			background:-moz-linear-gradient(-70deg, #009BB9 0%, #0EDCAD 100%);
			background:-ms-linear-gradient(-70deg, #009BB9 0%, #0EDCAD 100%);
			background:linear-gradient(90deg, #009BB9 0%,#0EDCAD 100%);
			background-repeat: no-repeat;
			background-size: 100% 100%;
		}
</style>
<head>

<script src="https://download.affectiva.com/js/3.2/affdex.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
<script type="text/javascript">


var width = 640;
var height = 480;
var detector;

onload = function () {
      var divRoot = document.getElementById("affdex_elements")

      //Construct a CameraDetector and specify the image width / height and face detector mode.
      detector = new affdex.CameraDetector(divRoot, width, height, affdex.FaceDetectorMode.LARGE_FACES);

      //Enable detection of all Expressions, Emotions and Emojis classifiers.
      detector.detectAllEmotions();
     /* detector.detectAllExpressions();
      detector.detectAllEmojis();
      detector.detectAllAppearance();*/

      //Add a callback to notify when the detector is initialized and ready for runing.
      detector.addEventListener("onInitializeSuccess", function() {
        log('logs', "The detector reports initialized");
        //Display canvas instead of video feed because we want to draw the feature points on it
      document.getElementById("face_video_canvas").style.display = "block";
      document.getElementById("face_video").style.display = "none";
      });

      //Add a callback to notify when camera access is allowed
      detector.addEventListener("onWebcamConnectSuccess", function() {
        log('logs', "Webcam access allowed");
      });

      //Add a callback to notify when camera access is denied
      detector.addEventListener("onWebcamConnectFailure", function() {
        log('logs', "webcam denied");
        console.log("Webcam access denied");
      });

      //Add a callback to notify when detector is stopped
      detector.addEventListener("onStopSuccess", function() {
        log('logs', "The detector reports stopped");
        document.getElementById("results").innerHTML = ""
      });

      //Add a callback to receive the results from processing an image.
      //The faces object contains the list of the faces detected in an image.
      //Faces object contains probabilities for all the different expressions, emotions and appearance metrics
      detector.addEventListener("onImageResultsSuccess", function(faces, image, timestamp) {
      document.getElementById("results").innerHTML = ""
        log('results', "Timestamp: " + timestamp.toFixed(2));
        if (faces.length > 0) {
          log('results', "Emotions: " + JSON.stringify(faces[0].emotions, function(key, val) {
            return val.toFixed ? Number(val.toFixed(0)) : val;
          }));
          drawFeaturePoints(image, faces[0].featurePoints);

    // Primitive UI for happy
    if (faces[0].emotions["joy"] > 85) {
      document.body.style.backgroundColor = "yellow";
    }
    else if (faces[0].emotions["anger"] > 85) {
      document.body.style.backgroundColor = "red";
    }
    else if (faces[0].emotions["sadness"] > 85) {
      document.body.style.backgroundColor = "blue";
    }
    else if (faces[0].emotions["surprise"] > 85) {
          document.body.style.backgroundColor = "purple";
    }

  }
      });
}

function log(node_name, msg) {
  document.getElementById(node_name).innerHTML += "<span>" + msg + "</span><br/>"
}

//function executes when Start button is pushed.
function onStart() {
  if (detector && !detector.isRunning) {
    document.getElementById("logs").innerHTML = ""
    detector.start();
  }
  log('logs', "Clicked the start button");
}

//function executes when the Stop button is pushed.
function onStop() {
  log('logs', "Clicked the stop button");
  if (detector && detector.isRunning) {
    detector.removeEventListener();
    detector.stop();
  }
};

//function executes when the Reset button is pushed.
function onReset() {
  log('logs', "Clicked the reset button");
  if (detector && detector.isRunning) {
    detector.reset();
    document.getElementById("results").innerHTML = ""
  }
}

//Draw the detected facial feature points on the image
function drawFeaturePoints(img, featurePoints) {
  var c = document.getElementById("face_video_canvas");
  if (c==null) return;
  var contxt = c.getContext('2d');

  var hRatio = contxt.canvas.width / img.width;
  var vRatio = contxt.canvas.height / img.height;
  var ratio = Math.min(hRatio, vRatio);

  contxt.strokeStyle = "#FFFFFF";
  for (var id in featurePoints) {
    contxt.beginPath();
    contxt.arc(featurePoints[id].x,
      featurePoints[id].y, 2, 0, 2 * Math.PI);
    contxt.stroke();
  }
}
</script>

</head>

<body>
  <div>
    <div>
      <button id="start" onclick="onStart()">Start</button>
      <button id="stop" onclick="onStop()">Stop</button>
      <button id="reset" onclick="onReset()">Reset</button>
      <h3>Emotion Commotion</h3>
    </div>

    <div class = "row">
    	<div class="col-lg-6">
    		<div id = "emotionImage"> <img src = images/angry1.jpg style = "width:580px;height:380px;"></div>
    	</div>

    	<div class="col-lg-6">
     	<div id="affdex_elements" style="width:680px;height:480px;"></div>
     	</div>
     
     </div>

    <br/>
    <br/>
    <div id="myui" style="color:red;"></div>
        </div>
        <div style="height:25em;">
          <strong>Emotion Tracking Results</strong>
          <div id="results" style="word-wrap:break-word;"></div>
        </div>
        <div>
          <strong>Detector Log Msgs</strong>
    <div id="logs"></div>
        </div>
    </div>
  </div
</body>
</html>
